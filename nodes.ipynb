{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjCRhDmXcIgYBGlV/QJVAY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrunalVaghela62/newww/blob/main/nodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtRb9Kl7LBVt"
      },
      "outputs": [],
      "source": [
        "import rclpy\n",
        "from rclpy.node import Node\n",
        "from sensor_msgs.msg import Image\n",
        "from std_msgs.msg import Float32MultiArray  # For publishing an array of centers\n",
        "from cv_bridge import CvBridge\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow  # Use cv2_imshow for Colab\n",
        "\n",
        "class ImageSubscriber(Node):\n",
        "    def __init__(self):\n",
        "        super().__init__('image_subscriber')\n",
        "\n",
        "        # Subscribe to the /image_raw topic where images are being published\n",
        "        self.subscription = self.create_subscription(\n",
        "            Image,  # Message type\n",
        "            '/image_raw',  # Topic name (to match the publisher topic)\n",
        "            self.listener_callback,  # Callback function to process the image\n",
        "            10  # QoS (Quality of Service) policy\n",
        "        )\n",
        "\n",
        "        # Publisher to publish center points to the /u_v topic\n",
        "        self.publisher_ = self.create_publisher(\n",
        "            Float32MultiArray,  # The message type to publish the centers\n",
        "            '/u_v',  # The topic where center coordinates will be published\n",
        "            10\n",
        "        )\n",
        "\n",
        "        self.bridge = CvBridge()\n",
        "\n",
        "    def listener_callback(self, msg):\n",
        "        # Convert the ROS Image message to an OpenCV image\n",
        "        frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n",
        "\n",
        "        # Define the color in BGR colorspace (yellow in this case)\n",
        "        yellow = [255, 0, 157]\n",
        "\n",
        "        # Precompute the HSV range for the target color\n",
        "        def get_precomputed_limits(color):\n",
        "            c = np.uint8([[color]])  # Convert to HSV\n",
        "            hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
        "            hue = hsvC[0][0][0]\n",
        "\n",
        "            # Handle wrap-around for hues\n",
        "            lower_limit = np.array([max(0, hue - 10), 100, 100], dtype=np.uint8)\n",
        "            upper_limit = np.array([min(180, hue + 10), 255, 255], dtype=np.uint8)\n",
        "\n",
        "            return lower_limit, upper_limit\n",
        "\n",
        "        # Get HSV bounds for yellow\n",
        "        lower_limit, upper_limit = get_precomputed_limits(yellow)\n",
        "\n",
        "        # Convert the image to HSV colorspace\n",
        "        hsv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Create a mask for the specified color (yellow)\n",
        "        mask = cv2.inRange(hsv_image, lower_limit, upper_limit)\n",
        "\n",
        "        # Find contours in the mask\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Loop over the contours and draw bounding boxes around them\n",
        "        centers = []\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            # Optionally, filter small contours by area\n",
        "            if w * h > 10:  # Set a minimum area threshold\n",
        "                # Draw the bounding box on the original frame\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
        "                centers.append((x + (w // 2), y + (h // 2)))\n",
        "        centers = np.array(centers)\n",
        "\n",
        "        # Display the processed image and print the center coordinates\n",
        "        cv2_imshow(frame)\n",
        "        center_msg = Float32MultiArray()\n",
        "        # Flatten the centers array and assign it to the message data\n",
        "        center_msg.data = centers.flatten().tolist()\n",
        "        self.publisher_.publish(center_msg)\n",
        "        self.get_logger().info(f\"Published centers: {centers.flatten()}\")\n",
        "\n",
        "def main(args=None):\n",
        "    rclpy.init(args=args)\n",
        "    image_subscriber = ImageSubscriber()\n",
        "\n",
        "    rclpy.spin(image_subscriber)\n",
        "\n",
        "    # Clean up\n",
        "    image_subscriber.destroy_node()\n",
        "    rclpy.shutdown()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rclpy\n",
        "from rclpy.node import Node\n",
        "from std_msgs.msg import Float32MultiArray  # Message type for the center points\n",
        "from geometry_msgs.msg import Point  # Message type for 3D world coordinates (X, Y, Z)\n",
        "import numpy as np\n",
        "\n",
        "def pixel_to_world(u, v, depth, K):\n",
        "    # Inverse of the intrinsic matrix\n",
        "    inv_K = np.linalg.inv(K)\n",
        "\n",
        "    # Convert pixel to normalized camera coordinates\n",
        "    pixel_coords = np.array([u, v, 1])  # Homogeneous image coordinates\n",
        "    normalized_coords = inv_K @ pixel_coords  # Apply inverse intrinsic matrix\n",
        "\n",
        "    # Scale normalized coordinates by depth to get camera coordinates\n",
        "    camera_coords = normalized_coords * depth  # [X_c, Y_c, Z_c]\n",
        "\n",
        "    # Extract world coordinates\n",
        "    X_w, Y_w, Z_w = camera_coords[:3]\n",
        "    return X_w, Y_w, Z_w\n",
        "\n",
        "\n",
        "class CenterSubscriber(Node):\n",
        "    def __init__(self):\n",
        "        super().__init__('center_subscriber')\n",
        "\n",
        "        # Subscribe to the /u_v topic where the centers are being published\n",
        "        self.subscription = self.create_subscription(\n",
        "            Float32MultiArray,  # Message type for the center points\n",
        "            '/u_v',  # Topic name (to match the publisher topic)\n",
        "            self.listener_callback,  # Callback function to process the data\n",
        "            10  # QoS (Quality of Service) policy\n",
        "        )\n",
        "\n",
        "        # Publisher to send the computed world coordinates to /motion_p topic\n",
        "        self.motion_publisher = self.create_publisher(\n",
        "            Point,  # The message type for the 3D world coordinates\n",
        "            '/motion_p',  # The topic where world coordinates will be published\n",
        "            10\n",
        "        )\n",
        "\n",
        "        # Example intrinsic camera matrix K\n",
        "        self.K = np.array([\n",
        "            [667.248390, 0.000000 ,644.165204],\n",
        "            [0.000000 ,668.783677, 417.422792],\n",
        "            [0.000000 ,0.000000 ,1.000000]\n",
        "        ])\n",
        "\n",
        "    def listener_callback(self, msg):\n",
        "        # Extract center points (flattened array)\n",
        "        centers = np.array(msg.data).reshape(-1, 2)\n",
        "\n",
        "        # Assuming random depths for example (replace with real depth data if available)\n",
        "        depths = np.random.rand(len(centers), 1) * 10  # Random depths between 0 and 10 meters\n",
        "\n",
        "        # Process each center and compute world coordinates\n",
        "        for (u, v), depth in zip(centers, depths):\n",
        "            X_w, Y_w, Z_w = pixel_to_world(u, v, depth, self.K)\n",
        "\n",
        "            # Log the world coordinates\n",
        "            self.get_logger().info(f\"World Coordinates: X={X_w}, Y={Y_w}, Z={Z_w}\")\n",
        "\n",
        "            # Create a Point message to publish the world coordinates\n",
        "            world_point = Point()\n",
        "            world_point.x = X_w\n",
        "            world_point.y = Y_w\n",
        "            world_point.z = Z_w\n",
        "\n",
        "            # Publish the world coordinates to the /motion_p topic\n",
        "            self.motion_publisher.publish(world_point)\n",
        "            self.get_logger().info(f\"Published world point: {world_point}\")\n",
        "\n",
        "def main(args=None):\n",
        "    rclpy.init(args=args)\n",
        "    center_subscriber = CenterSubscriber()\n",
        "\n",
        "    rclpy.spin(center_subscriber)\n",
        "\n",
        "    # Clean up\n",
        "    center_subscriber.destroy_node()\n",
        "    rclpy.shutdown()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "PHHcV6AWLHd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TiOO2iPLJMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}